# 3.1 损失函数 Loss Function

##  3.1.1 介绍 Introduction

手动的方法，用人眼看一下这些分数，哪些是好的，哪些是坏的。但是如果为这些写一个算法自动决定哪些 $W$ 是最优的，就需要一个度量任意某个 $W$ 的好坏的方法。可以用一个函数把 $W$ 作为输入，然后看一下得分，定量地估计 $W$ 的好坏，这个函数叫做**损失函数**。我们有了损失函数的概念之后，那么就可以定量地衡量任意一个 $W$，到底是好是坏。我们要找到一种有效的方式，来从 $W$ 的可行域里，找到 $W​$ 取什么值是最不坏的情况，这个过程是一个**优化过程**。我们在这节课在这个简单的三个样本对应三个类的例子中，来看看具体怎么操作。

This is kind of a hand way approach, just looking at the scores and eyeballing which ones are good and which ones are bad. But to actually write algorithms about these things and to actually to determine automatically which $W$ will be best, we need some way to quantify the badness of any particular $W$. And that's this function that takes in a $W$, looks at the scores and then tells us how bad quantitatively is that $W$, is something that we'll call a **loss function**. So then once we've got this idea of a loss function, this allows us to quantify for any given value of $W$, how good or bad is it. But then we actually need to find and come up with an efficient procedure for searching through the space of all possible $W$s，and actually come up with what is the correct value  of $W$ that is the least bad, and this process will be an **optimization procedure**. So we'll work with this tiny toy data set of three examples and three classes going forward in this lecture.

## 3.1.2 案例 Example

------

Suppose: 3 training examples, 3 classes

With some $W​$ the scores 
$$
f(X, W) = WX
$$

<center class="third">
    <img src=".\images\3.1_01_cat.png">
    <img src=".\images\3.1_02_car.png">
    <img src=".\images\3.1_03_frog.png">
</center>

| catgory | score   | score   | score    |
| ------- | ------- | ------- | -------- |
| cat     | **3.2** | 1.3     | 2.2      |
| car     | 5.1     | **4.9** | 2.5      |
| frog    | -1.7    | 2.0     | **-3.1** |

------

这个例子里，猫的分类不对，车子分对了，从这个 $W$ 来说青蛙的图片是彻底地分错类了，因为青蛙的分数甚至比其他类别都要低。

In this example, the cat is maybe not correctly classified, the car is correctly classified, and the frog,  this setting of $W$ got this frog image totally wrong,  because the frog score is much lower than others.

正式一点来说，一般我们所谓的损失函数，有一些训练数据集 $x$ 和 $y$，其中 $x$ 是算法的输入，在图片分类问题里，$x$ 其实是图片每个像素点所构成的数据集，$y​$ 是希望算法预测出来的东西，通常称为标签或目标。

So to formally this a little bit, usually when we talk about a loss function, we imagine that we have some training data set of xs and ys,  usually N examples of these where the xs are the inputs to the algorithm in the image classification case,  the xs would be the actually pixel values of your images, and the ys will be the things you want your algorithm to predict, we usually call these the labels or the targets.

在图片分类问题里，要记住我们是在尝试把 CIFAR-10 中的每个图片，分类到 10 个类的 1 个里。所以标签 $y$ 是一个在 1 到 10 之间的整数，或者 0 到 9 也是一样的，这取决于你的程序。这个整数表明对每个图片 $x$ 哪个类是正确的。

So in the case of image classification, remember we're trying to categorize each image for CIFAR-10 to one of 10 categories, so the label $y$ here will be an integer between one and 10 or maybe between zero and nine, depending on what programming language you're using. But it'll be an integer telling you what is the correct category for each one of those images $x$.

------

A loss function tells how good our current classifier is.

Given a dataset of examples
$$
{\{(x{}{_i},y{}{_i}})\}{}{^N_{i=1}}
$$
Where $x_i$ is image and $y_i​$ is (integer) label.

Loss over the dataset is a sum of loss over examples:
$$
L=\frac{1}{N}\sum_{i}L{}{_i}(f(x{}{_i},W),y{}{_i})
$$

------

我们有了这个关于 $x​$ 的预测函数之后，这个函数就是通过样本 $x​$ 和权重矩阵 $W​$ 给出 $y​$ 的预测。在图片分类问题中，就是给出 10 个数字中的一个，我们可以给出一个损失函数 $L_i​$ 的定义，通过函数 $f​$，和真实的目标，或者说标签 $y​$，可以定量地描述训练样本预测得好不好。最终的损失函数 $L​$ 是在整个数据集中 $N​$ 个样本点的损失函数的总和的平均。

So then we have this prediction function which takes in our example $x$ and our weight matrix $W$ and make some prediction for $y$. In the case of image classification these will be our 10 numbers. Then we'll define some loss function $L_i$, which will take in the predicted scores coming out of the function f together with the true target or label $y$, and give us some quantitative value for how bad those predictions are for that training example. And now the final loss $L$ will be the average of these losses summed over the entire data set over each of the $N$ examples in our data set.

这是一个很通用的公式，可以拓展到图片分类以外的问题。可以拓展到其他任务其他例子和深度学习。对任何问题这可以说是一个通用的设置，有了 $x​$ 和 $y​$ 你想要用某个损失函数，定量地描述出参数 $W​$ 是否令人满意。然后在所有的 $W​$ 中，找到在训练集上损失函数极小化的 $W​$。

So this is actually a very general formulation and actually extends  even beyond image classification. Kind of as we move forward and see other tasks, other examples of tasks and deep learning, the kind of generic setup is that for any task you have some xs and ys and you want to write down some loss function that quantifies exactly how happy you are with particular parameter settings $W$, and then you'll eventually search over the space of $W$ to find the $W$ that minimizes the loss on your training data.

作为第一个具体的损失函数的例子，同时这个例子和图片分类结合起来也是合适的。我们将要介绍多分类 SVM 损失函数。

So as a first example of a concrete loss function, that is a nice thing to work with in image classification, we'll talk about the multi-class SVM loss.

## 3.1.3 SVM 损失函数 SVM Loss Function

对于单个例子的损失函数 $L_i​$，我们的计算方式，除了真实的分类 $Y_i​$ 以外，对所有的分类 $Y​$ 都做加和，也就是说在所有错误的分类上求和，比较正确分类的分数和错误分类的分数。如果正确分类的分数比错误分类的分数高出某个安全边距，我们把这个边距设为 1， 如果说真实分类的分数比其他任何错误分类的分数都要高很多，那么损失为 0。

The loss $L_i$ for individual example, the way we'll compute it is we're going to perform a sum over all of the categories, $Y$,  except for the true category, $Y_i$, so we're going to sum over all the incorrect categories, and then we're going to compare the score of the correct category, and the score of the incorrect category. And now if the score for the correct category is greater than the score of the incorrect category, by some safety margin, that we set to one, if that's the case that means the true score is much larger than any of the false categories, then we'll get a loss of zero.

接下来把图片对每个错误分类的损失加起来，就可以得到数据集中这个样本的最终损失。然后还是一样的对整个训练集取平均。这有点像 if then 语句，就是说如果真实类的分数比其他都高很多。这种 if then 结构，我们通常把他们缩写成 $max(0, S_j-S_{Y_i})​$ 再加上一点东西。

And we'll sum this up over all of the incorrect categories for our image and this will give us our final loss for this one example in the data set. And again we'll take the average of this loss over the whole training data set. So this kind of like if then statement, like if the true class score is much larger than the others. This kind of if then formulation we often compactify into $max(0, S_j-S_{Y_i})​$ plus one thing.

------

**Muliticlass SVM loss:**

Given an example $(x_i, y_i)​$, where $x_i​$ is the image and where $y_i​$ is the (integer) label, and using the shorthand for the scores vector.
$$
s = f(x{}{_i},W)
$$
*<u>$S$ 是通过分类器预测出来的类的分数，如果 1 是猫类，2 是狗类，那么 $S_1$ 和 $S_2$ 分别就是猫和狗的分数。</u>*

*<u>Ss are the predicted scores for the classes that are coming out of the classifier. Like if one is the cat class and two is the dog class the $S_1$ and $S_2$ would be the cat and dog scores respectively.</u>*

*<u>要记住  $Y_i$ 表示这个样本的正确的分类标签。</u>*

*<u>And remember we said that $Y_i$ was the category of the ground truth label for the example which is some integer.</u>*

 <u>所以 $S_{y_i}$ 就代表了训练集的第 i 个样本的真实分类的分数。</u>

*<u>So $S_{y_i}$ that corresponds the score of the true class for the i-th example in the training set.</u>*

the SVM loss has the form:
$$
L{}{_i} =\sum_{_j\neq y{}{_i}} \begin{cases}
        0,  & \text{if $s{}{_{ y{}{_i}}{}}$  $\geq$ $s{}{_j} +1$} \\
        s{}{_j} - s{}{_{ y{}{_i}}{}} + 1, & \text{otherwise}
        \end{cases}
        =\sum_{_j\neq y{}{_i}}max(0, s{}{_j} - s{}{_{ y{}{_i}}{}} + 1)
$$

<center>
    <img src=".\images\3.1_04_hinge-loss.png">
</center>
------

顺便一提，这种某个值和 0 取较大值的损失函数也可以说是一个合页损失函数，这个名字是来源于函数的图像。这里 $x​$ 轴表示 $S_{Y_i}​$，是训练样本真实分类的分数，$y​$ 轴是损失，可以看到随着真实分类的分数提升，损失会线性下降，一直到分数超过了一个阈值，损失函数就会是 0，因为我们对这个样本成功地分了类。

And by the way, this style of loss function where  we take max of zero and some other quantity is often referred to as some type of a hinge loss,  and this name comes from the shape of the graph. Here the x axis corresponds to the $S_{Y_i}$, that is the score of the true class for some training example, and now the y axis is the loss, and you can see that as the score for the true category for this example increases, then the loss will go down linearly until  we get to above this safety margin, after which the loss will be zero，because we've already correctly classified this example.

*这个公式到底在算什么呢？这个损失是在说如果真实分类的分数比其他的分数高很多，那我们就很满意。需要高出多少呢？要高出一个安全的边距，如果真实分类的分数还不够比其他分类高出那么多，那么我们会得到一些损失，这是不好的情况。*

*What exactly is this computing here? What this loss is saying is that we are happy if the true score is much higher than all the other scores. It needs to be higher than all the other scores by some safety margin, and if the true score is not high enough, greater than any of the other scores, then we will incur some loss and that would be bad.*

------
<center>
    <img src=".\images\3.1_05_manupulation-calculation-1.png">
</center>
---------------------

如果我们对第一个训练样本计算多分类 SVM 损失函数，我们要对所有不正确的分类都循环一遍，那么就这个例子来看，猫是正确的分类，所以我们要对汽车和青蛙都做一遍运算，来看汽车，汽车的分数 $S_j​$ 5.1 减去猫的分数  $S_{y_i}​$​ 3.2，再加上 1 ，我们比较猫和车的时候，我们会得到一些损失，因为车的分数比猫的分数要高，这是不好的。对这个类，对这个样本来说，我们的得到了 2.9 的损失值。接下来我们比较猫的分数和青蛙的分数，青蛙分数是 -1.7，猫是 3.2，所以猫的得分超出青蛙得分 1 分以上，这表明这两个类别的损失函数为 0.

If we think about computing this multi-class SVM loss for just this first training example, remember we're going to loop over all of the incorrect classes, so far this example, cat is the correct class, so we're going to loop over the car and frog classes, and now for car, we're going to look at the car score, 5.1, minus the cat score, 3.2, plus one, when we're comparing cat and car we expect to incur some loss here because the car score is greater than the cat score which is bad. So for this one class, for this one example, we'll incur a loss of 2.9, and then when we go and compare the cat score and frog score we see that frog score is minus 1.7 and cat score is 3.2, so cat is more than one greater than frog, which means that between these two classes we incur zero loss.

训练样本的多分类支持向量机损失函数是每一个对这样的类别构成的损失项的加和，也就是 2.9 加上 0，即 2.9。这也一定程度上表明 2.9 是我们的分类器对于这一个训练样例训练得多好的一个量化衡量指标。

So then the multiclass SVM loss for this training example will be the sum of the losses acorss each of these pairs of classes, which will be 2.9 plus zero which is 2.9. Which is sort of saying that 2.9 is a quantitative measure of how much our classifier screwed up on this one training example.

------

<center>
    <img src=".\images\3.1_05_manupulation-calculation-2.png">
</center>

<center>
    <img src=".\images\3.1_05_manupulation-calculation-3.png">
</center>

<center>
    <img src=".\images\3.1_05_manupulation-calculation-4.png">
</center>
------

最终，我们对整个训练数据集的损失函数是这些不同的样例的损失函数的平均值，所以当你相加这些损失函数求平均值后得到了 5.3。这一定程度上是我们的量化衡量，5.3 反应了我们的分类器在数据集上有多不好。

And then our final loss for the entire data set is the average of these losses across the different examples,  so when you sum those out it comes to about 5.3. So then it's sort of, this is our quantitative measure that our classifier is 5.3 bad on this data set.

## 3.1.4 问答 Question and Answer

*第一个问题是如果我们稍微改变了汽车的分数，损失函数会发生什么变化吗？*

*So the first question is what's going to happen to the loss if we change the scores of the car image just a little bit?*

*如果汽车的分数发生了轻微变化，那么损失函数将不会变化。SVM 函数，只关注于正确的分数比不正确的分数大过 1，但是在这种情况下，汽车的分数比其他的都要大，所以如果汽车的分数只是改变了一点点，那么 1 的界限依然奏效，损失函数并不会改变，我们依然得到为 0 的损失函数。*

*If we jiggle the scores for this car image a little bit, the loss will not change. So the SVM loss, remember, the only thing it cares about is getting the correct score to be greater than one more than the incorrect scores, but in this case, the car score is already quite a bit larger than the others, so if the scores for this class changed for this example, changed just a little bit, this margin of one will still be retained and the loss will not change, we'll still get zero loss.*

*另一个问题， SVM 损失函数的可能的最大最小值是多少？*

*Question two, what's the min and max possible loss？*

*损失函数的最小值是 0。你可以想象所有的分类，如果我们的正确分数非常大，那么我们会得到所有分类的损失函数为 0，那么损失函数就为 0。回想一下合页损失函数，那么你可以看到如果正确分类的分数是绝对值很大很大的负数，那么我们可能会得到很大的损失函数。所以最小值是 0，最大值是无穷大。*

*So the minimum loss is zero, because if you can imagine that across all the classes, if our correct score was much larger then we'll incur zero loss across all the classes and it will be zero. And if you think back to this hinge loss plot that we had, then you can see that if the correct score goes very, very negative, then we could incur potentially infinte loss. So the min is zero, and the max is infinity.*

*另一个问题，当你初始化这些参数，并且从头开始训练，通常你先用一些很小的随机值来初始化 $W​$，你的分数的结果在训练的初期倾向于呈现较小的均匀分布的值。问题是如果所有的 $S​$，也就是所有的分数都近乎为 0，并且差不多相等，损失函数预计会是如何呢？*

*Question three, sort of when you initialize these things and start training from scratch, usually you kind of initialize $W$ with some small random values, as a result your scores tent to be sort of small uniform random values at the begining of training. And then the question is that if all of your $S$s,  if all of the scores are approximately zero, and approximately equal, then what kind of loss do you expect when you're using multiclass SVM?*

*答案是分类的数量减去 1。因为如果我们对所有不正确的类别进行遍历，那么实际上遍历了 $C - 1​$ 次遍历。在这些类别中的每一个，这两个分数差不多相同，因为存在着 1 的边界，所以我们会得到一个值为 1 的损失项，我们将会得到 $C - 1​$。这是个有用的调试策略，当你开始训练的时候，你应该想到你预期的损失函数该是多大，如果在刚开始训练的时，在第一次迭代的时候损失函数并不等于 $C - 1​$，这意味着程序可能有 bug，得去检查一下代码，所以在实际应用中这是一个有用的结论。*

*The answer is number of classes minus one, because remember that if we're looping over all of the incorrect classes, so we're looping over $C - 1$ classes, within each of those classes, the two Ss will be about the same, so we'll get a loss of one because of the margin and we'll get $C - 1$. This is a useful debugging strategy when you're using these things, that when you start off training, you should think about what you expect your loss to be, and if the loss you actually see at the start of training at the first iteration is not equal to $C - 1​$ in this case, that means you probably have a bug and you should go check your code, so this is actually kind of a useful thing to be checking in practice.*

*问题四，之前说过我们对所有错误分类的分数进行求和，如果我们将所有正确的分数也求和会发生什么呢？求和包括所有的分类得分。(包括正确分类的得分)*

*Another question, what happens if, so I said we're summing an SVM over the incorrect classes, what happens if the sum is also over the correct class if we just go over everything? What if the sum was over all classes? (including $j = y_i$)*

*答案是损失函数增加了 1。我们在实际应用中这么做的原因在于通常损失函数为 0 时说明算法很好，没有损失什么，这很好，所以答案不会改变，如果你实际上求和遍历了所有的类别，就不用再去找同样的分类器了。但是我们忽略了正确的类别，那么我们的最小损失函数为 0。*

*The answer is that the loss increases by one. And I think the reason that we do this in practice is because normally loss of zero is kind of, has this nice interpretation that you're not losing at all, so that's nice, so I think your answers wouldn't really change, you'll end up finding the same classifier if you actually looped over all the categories, but if just by conventions we omit the correct class, so that our minimum loss is zero.*

*问题五，如果我们使用平均值而不是用求和呢？*

*So another question, what if we used mean instead of sum here?*

*答案是这不会改变。所以当我们选择数据集的时候，分类的数量要提前确定。因为这只是将整个损失函数缩小了一个倍数，所以这并没有什么影响，任何的缩放操作都不会有什么影响，因为我们实际上并不在意真正的分数值或者是损失函数的真实值。*

*The answer is that it doesn't change. So the number of classes is going to be fixed ahead of time when we select our data set, so that's just rescaling the whole loss function by a constant, so it doesn't really matter, it'll sort of wash out with all the other scale things because we don't actually care about the true values of the scores, or the true value of the loss.*

*问题六，如果我们改变损失函数，在 max 上加一个平方项呢？这还是同一个问题吗或者这会成为另一个不同的分类算法吗？*
$$
L{}{_i} =\sum_{_j\neq y{}{_i}}max(0, s{}{_j} - s{}{_{ y{}{_i}}{}} + 1){^2}
$$
*What if we change this loss formulation and we actually added a square term on top of this max？ Would this end up being the same problem or would this be a different classfication algorithm?*

*这是不同的。平方的想法在于我们用一种非线性的方法改变了在好和坏之间的权衡，实际上我们计算了另一种损失函数。关于合页损失函数的平方项的想法有时候确实会在实际中使用，这是另一个当你针对自己的问题，构成损失函数时的技巧。*

*This is different. So here the idea is that we're kind of changing the trade-offs between good and badness in kind of a nonlinear way, so this would end up actually computing a different loss function. This idea of a squared hinge loss actually does get used sometimes in practice, so that's kind of another trick to have in your bag when you're making up your own loss functions for your own problems.*

*问题在于你考虑使用一个平方损失函数而不是非平方项的损失函数？*

*So the question is why would you ever consider using a squared loss instead of a non-squared loss?*

*一个损失函数的全部意义在于量化不同的错误到底有多坏。同时分类器会犯不同的错误，我们如何对分类器可能犯的不同类型的错误进行权衡。如果你使用平方损失函数，这意味着一个非常非常不好的错误，就会更加不好，成平方地不好。我们并不想要任何被严重分错的结果。如果你使用合页损失函数，我们对微小的错误并不在意。但是如果一个样例中出现了很多错误，那么我们就扩大错误，以此来减小这个错误。这就像，一个仅仅有微少错误的样例扩大错误以此来纠正为更加正确。所以这是一个有点波浪，但是这个使用线性与平方的思想，是量化我们关心不同类别错误多少的一种方法。这绝对是你在实践中实际应用这些东西的时候应该考虑的事情，因为损失函数就是这样，你告诉你的算法你关心的是什么类型的错误，什么类型的错误可以折衷。所以这在实践中非常重要，取决于你的应用。*

*The whole point of a loss function is kind of quantify how bad are different mistakes. And if the classifier is making different sorts of mistakes, how do we weigh off the different trade-offs between different types of mistakes the classifier might make? So if you're using a squared loss, that sort of says things that are very, very bad are now getting to be squared bad, we don't want any thing that's totally catastrophically misclassified. As if you're using this hinge loss, we don't actually care between being a little bit wrong, kind of like if an example is a lot wrong, and we increase it and make it a little bit less wrong. That's kind of the same goodness as an example which was only a little bit wrong and then increasing it to be a little bit more right. So that's a little hand wavy, but this idea of using a linear versus a square is a way to quantify how much we care about different categories of errors. And this is definitely something that you should think about when you're actually applying these things in practice, because the loss function is the way that you tell your algorithm what types of errors you care about and what types of errors it should trade off against. So that's actually super important in practice depending on your application.*

------

<center>
    <img src=".\images\3.1_06_question-7.png">
</center>
------

*问题七，假设你很幸运找到一个 $W​$，损失值为 0，这个 $W​$ 唯一吗？*

*Another question about this loss function. Suppose that you were lucky enough to find a $W$ that has loss of zero, is this $W$ unique or were there other Ws that could also have achieved zero loss?*

*不是唯一的，我们说过把整个问题扩大或者缩小的事情取决于 $W​$，我们把 $W​$ 乘以 2，这个 2 倍的 $W​$ 也将实现零损失。*

*There are definitely other Ws. And in particular, because we talked a little bit about this thing of scaling the whole problem up or down depending on $W$, so you could actually take $W$ multiplied by two and this doubled $W$ would also achieve zero loss.*

*所以作为一个具体的例子，你可以回到你最喜欢的例子并可能通过数字工作，但如果让 $W​$ 加倍，正确与不正确的安全边际值，也会翻倍。所以如果所有这些安全边际都大于 1，结果我们就对其翻倍，其值也会大于 1，结果损失函数值依然为 0。*

*So as a concrete example of this, you can go back to your favorite example and maybe work through the numbers a little bit later, but if you're taking $W$ and we double $W$, then the margins between the correct and incorrect scores will also double. So that means that if all these margins were already greater than one, and we doubled them, they'll still going to be greater than one, so you'll still have zero loss.*

## 3.1.5 正则化 Regularization

如果损失函数是要告诉我们的分类器哪个 $W​$ 是我们想要的哪个 $W​$ 是我们关心的，分类器到底如何在这些都是 0 值的损失函数间选择。

If the loss function is the way that tell our classifier which $W$ we want and which $W$ we care about, now there's this inconsistency and how the classifier to choose between these different versions of $W$ that all achieve zero loss?

那是因为我们在这里所做的只是在数据方面的损失，我们仅仅告诉分类器他需要尝试找到可以拟合训练集的 $W$。但是实际上，我们并不那么关心拟合训练数据，机器学习的重点，是我们使用训练数据来找到一些分类器，然后将其用于测试数据。所以我们并不关心在训练集的表现，我们关心分类器在测试集上的表现。所以，如果我们仅仅告诉分类器，你只需要拟合训练集的话，就有可能导致我们陷入尴尬的境地，你会发现分类器可能会行为反常。

And that's because what we've done here is written down only a loss in term of the data, and we only told our classifier that it should try to find the W that fits the training data. But really in practice, we don't actually care about that much about fitting the training data, the whole point of machine learning is that we use the training data to find some classifier and then we'll apply that thing on test data. So we don't really care about the training data performance, we really care about the performance of this classifier on test data. So as a result, if the only thing we're telling our classifier to do is fit the training data, then we can lead ourselves into some of weird situations sometimes, where the classifier might have unintuitive behavior.

------

<center>
    <img src=".\images\3.1_07_overfitting.png">
</center>
------

这是一个具体的、典型的例子，顺便说一句，这不是线性分类器了，这是一个更广义的机器学习的概念。假设我们有这样的数据集，就是图中的蓝点，并且我们为训练数据拟合曲线，我们告诉分类器做的唯一的事情是拟合训练数据，结果可能会拟合出非常曲折的曲线以尝试完美分类所有的训练数据点。但这很糟糕，因为我们实际上并不关心这个表现，我们关心测试数据的性能。如果现在我们有新的数据进来（绿色方点），这种趋势也是如此，那么这个蓝色的曲线将是完全错误的。事实上，我们可能会喜欢分类器预测的这条绿色的直线，而不是这个完全拟合所有训练数据的非常复杂的曲线。

So a concrete, canonical example of this sort of thing, by the way this is not linear classification anymore, this is a little bit of a more general machine learning concept. Suppose we have this data set of blue points,  and we're going to fit some curve to the training data, the blue points, then the only thing we've told our classifier to do is to try and fit the training data, it might go in and have very wiggly curves to try to perfectly classify all of the training data points. But this is bad, because we don't actually care about this performance, we care about the performance on the test data. So now if we have some new data come in, that sort of follows the same trend, then this very wiggly blue line is going to be totally wrong. And in fact, what we probably would have preferred the classifier to do was maybe predict this straight green line, rather than this very complex wiggly line to perfectly fit all the training data.

这是在机器学习领域里是一个非常核心的基础性问题，通常我们解决的方式是正则化。我们为损失函数添加一个附加的项。除了 data loss 之外（用来告诉分类器需要拟合训练集），我们通常会添加一个项到损失函数里，这个项称为正则项，鼓励模型以某种方式选择更简单的 $W​$，这里所谓的简约，取决于任务的规模和模型的种类。这里实际上也体现了奥卡姆剃刀的理念，也就是科学发现最基本的思想，如果你有多个可以解释观察结果的假设，一般来讲，应该选择最简约的，因为这样可以在未来将其用于解释新的观察结果。

And this is a core fundamental problem in machine learning, and the way we usually solve it, is this concept of regularization. So here we're going to add an additional term to the loss function. In addition to the data loss, which will tell our classifier that it should fit the training data, we'll also typically add another term to the loss function called a regularization term, which encourages the model to somehow pick a simpler $W​$, where the concept of simple kind of depends on the task and the model. There's this whole idea of Occam's Razor, which is this fundamental idea in scientific discovery more broadly, which is that if you have many different competing hypotheses that could explain your observations, you should generally prefer the simpler one, because that's the explanation that is more likely to generalize to new observations in the future. 

我们在机器学习中运用这种直觉的方式，我们会直接假设正则化惩罚项，通常记作 $R​$。这样一来，标准损失函数有了两项，数据丢失项和正则项，这有一些超参数，$λ​$，用来平衡这两项。我们在上一讲中讨论了超参数并进行交叉验证，所以这个超参数 $λ​$ 是在实际训练模型时重点调参的。

And the way we operationalize this intuition in machine learning is typically through some explicit regularization penalty, that's often written down as R. So then your standard loss function usually has two terms, a data loss and a regularization loss, and there's some hyper-parameter here, λ, that trades off between the two. And we talked about hyper-parameters and cross-validation in the last lecture, so this regularization hyper-parameter λ will be one of the more important ones that you'll need to tune when training these models in practice.

*$λ​$ $R​$ $W​$ 这三项之间有什么相互作用？实际上主要是为了让很弯曲的拟合线变成一条直线？*

*What's the connection between this $λ$ $R$ $W$ term? Actually forcing this wiggly line to become a straight green line?*

*你可以想象正在做一个回归问题，也许模型确实非常逼近高幂次多项式函数，但是，通过加入这个回归项，就可以让模型的幂次数降低。可以想象有两种方法做到这点，一种是限制模型，不要更高的阶数或过于复杂的模型，另一种就是加入这个惩罚项，这样一来，模型依然可以逼近复杂模型的效果。比如这个例子中的高幂次多项式，即想用这些更复杂的模型，必须克服这个惩罚。*

*You can imagine you're doing a regression problem in terms of different polynomial basis functions, and if you're adding this regression penalty, maybe the model has access to polynomials of very high degree, but through this regression term, you could encourage the model to prefer polynomials of lower degree, if the fit the data properly, or if they fit the data relatively well. So you could imagine there're two ways to do this, either you can constrain your model class to just not contain the more powerful, more complex models, or you can add this penalty where the model still has access to more complex models, maybe high degree pilynomials in this case, but you add this soft constraint saying that if you want to use these more complex models, you need to overcome this penalty for using their complexity.*

------

<center>
    <img src=".\images\3.1_08_regularization.png">
</center>
------

实际上在实践使用中有很多不同的类型的正则化，最常见的可能是 $L2​$ 正则化或权值衰减。还有很多其他的。$L2​$ 正则化就是权重向量 $W​$ 的欧式范数，或者有时平方范数、平方范数的一半，因为这会让你的推导变成现实。$L2​$ 正则化的理念实际上是对这个权重向量的欧式范数进行惩罚。有时也会看到 $L1​$ 的正则化，我们正在处罚权值向量的 $L1​$ 范数，$L1​$ 正则化有一些很好的性质，比如在这个矩阵 W 中鼓励稀疏。还有弹性网络正则化（是 $L1​$ 和 $L2​$ 的组合）、最大范数正则化（惩罚最高准则而不是 $L1​$ 或 $L2​$）、Dropout、批量归一化、随机深度。**正则化的宏观概念就是你对模型做的任何事情也就是种种所谓的惩罚主要是为了减轻模型的复杂程度，而不是去试图拟合数据。**

So there's actually a lot of different types of regularization that get used in practice. The most common one is probably $L2​$ regularization or weight decay. But there's a lot of other ones that you might see. This$L2​$ regularization is just the euclidean norm of this weight vector $W​$, or sometimes the squared norm, or sometimes half the squared norm, because it make your derivatives work out a little bit nicer. But the idea of $L2​$ regularization is you're just penalizing the euclidean norm of this weight vector. You might also sometimes see $L1​$ regularization where we're penalizing the $L1​$ norm of the weight vector, and the $L1​$ regularization has some nice properties like encouraging sparsity in this matrix W. Some other things you might see would be this elastic net regularization which is some combination of $L1​$ and $L2​$. You sometimes see max norm regularization penalizing the max norm rather than the $L1​$ or $L2​$ norm. Dropout or batch normalization, stochastic depth. **But the whole idea of regularization is just any thing that you do to your model, that sort of penalizes somehow the complexity of the model, rather than explicitly trying to fit the training data.**

------

<center>
    <img src=".\images\3.1_09_L1-L2-regularization.png">
</center>
------

我们有一些训练的样本 $x​$，有两个不同的候选 $W​$，$x​$ 是一个包含 4 个 1 作为元素的四维向量，我们来考察这两个不同的 $W​$。第一个是首元素是 1，另外三个元素是 0，另一种是四个元素都是 0.25。进行线性分类时，我们真正讨论的是 $x​$ 与 $W​$ 的点乘结果，在线性分类的语境下，这两个 $W​$ 是一样的，因为点乘结果相同。当观察这两个例子，哪种情形下 $L2​$ 回归性会好一些？每个元素是 0.25 的 $W​$ 的 $L2​$ 回归性会好一些，因为它有比较小的范数。$L2​$ 用一种相对粗糙的方式去度量分类器的复杂性。在线性分类器中，$W​$ 所反映的是 $x​$ 向量的值在多大程度上对输出有影响。所以 $L2​$ 正则化的作用是它能更加传递出 $x​$ 中不同元素值的影响。它的鲁棒性可能会更好一些，当你输入的 $x​$ 存在变化的时候，我们的判断会铺展开来，并主要取决于 $x​$ 向量的整体情况，而不是仅取决于 $x​$ 中的某几个特定元素。另外，$L1​$ 正则化有完全相反的解释，我们采用 $L1​$ 正则化时，更倾向于首元素是 1，其他元素是 0 的 $W​$，因为 $L1​$ 正则化对复杂性有不同的概念，通过向量中 0 的个数来体现复杂性。它们视问题的不同而定，针对特殊的模型和数据以及不同的设置，都要仔细考虑，在该项任务中复杂度应该如何度量。

Here we have some training example, $x​$, and there're two different $W​$s that we're considering. $x​$ is just this vector of four ones,  and we're considering these two different possibilities for $W​$. One is a single one and three zeros, and the other has this 0.25 across the four different entries. When we're doing linear classification, we're taking dot products between our $x​$ and our $W​$. In terms of linear classification, these two $W​$s are the same, because they give the same result when dot producted with $x​$. If you look at these two examples, which one would $L2​$ regression prefer? $L2​$ regression would prefer $W_2​$, because it has a smaller norm. $L2​$ measures complexity of the classifier in this relatively coarse way. The $W​$s in linear classification had this interpretation of how much does this value of the vector $x​$ correspond to this output class. So $L2​$ regularization is saying that it prefers to spread that influence across all the different values in $x​$. Maybe this might be more robust, in case you come up with $x​$s that vary, then our decisions are spread out and depend on the entire $x​$ vector, rather than depending only on certain elements of the $x​$ vector. By the way, $L1​$ regularization has this opposite interpretation. When we were using $L1​$ regularization, then we would actually prefer $W_1​$ over $W_2​$, because $L1​$ regularization has this different notion of complexity,  we measure model complexity by the number of zeros in the weight vector. The question i show do we measure complexity and how does $L2​$ measure complexity? They‘re kind of problem dependent. You have to think about for your particular setup, for your particular model and data, how do you think that complexity should be measured on this task?

## 3.1.6 Softmax 损失函数 Softmax loss function

除了多类别 SVM 损失函数之外，深度学习中另一个非常流行的选择，是多项逻辑斯蒂回归，或者叫 softmax loss。这个损失函数在深度学习里，可能使用得更为广泛。

In addition to the multi-class SVM loss, another popular choice in deep learning, is multinomial logistic regression, or a softmax loss. And this one is a bit more common in the context of deep learning.

回想一下多类别 SVM 损失函数的背景，针对得分，我们并没有一个解释。当我们在做线性分类时，模型函数 $F​$，输出了 10 个数字，这些数字代表了这些类别的得分，针对多类别的 SVM，我们并没有对这些得分多做解释。只是说想要正确类别的得分应该比不正确的类别得分要高才好，除此之外并没有解释这些得分的真正含义。但对于多项逻辑斯蒂回归损失函数，我们将赋予这些得分一些额外的含义。并且我们会用这些分数针对我们的类别去计算概率分布。

Remember in the context of the multi-class SVM loss, we don't acutally have an interpretation for those scores. When we're doing some classification, our model $F$, spits these 10 numbers, which are scores for the classes, and for the multi-class SVM, we didn't give much interpretation to those scores. We just said that we want the true score, the score of the correct class to be greater than the incorrect classes, and beyond that we don'y really say what those scores men. But for the multinimial logistic regression loss function, we will endow those scores with some additional meaning. And in particular we're going to use those scores to compute a probability distribution over our class.

------

<center>
    <img src=".\images\3.1_10-softmax.png"> 
</center>
------


当我们讨论分数时，我们将用这个所谓的 softmax 函数，将其指数化以便结果都是正数，然后利用这些指数的和来归一化他们。当我们将分数经过 softmax 函数处理之后，我们得到了概率分布，对于所有类别我们都有了相应概率，介于 0 和 1 之间，所有类别的概率和为 1。这正是我们所期待的解释，这是计算出来的概率分布，是从分数推导出来的，我们拿它与我们的目标值或者说真实的概率分布进行比较。如果我们知道那个东西是一只猫时，目标的概率分布应该把所有的概率集中在猫上面，所以可以得到猫的概率是 1，而对于其他类别而言概率是 0。现在我们需要做的是去促使我们计算得到的概率分布就是那个通过 softmax 计算的结果，去匹配上述的目标概率分布。即正确的类别应该具有几乎所有的概率。

We use this so-called softmax function where we take all of our scores, we exponentiate so that now they become positive, then we re-normalize them by the sum of those exponents. After we send our scores through this softmax function, now we end up with this probability distribution, where we now have probabilities over our classes,  each probability is between zero and one, and the sum of probabilities across all classes is 1. And the interpretation is that we want, there's computed probability distrubution that's implied by our scores, and we want to compare this with the target or true probability distribution. So if we know that the thing is a cat, then the target probability distribution would put all of the probability mass on cat, so we have probability of cat equals one, and zero probability for all the other classes. Sonow what we want do do is encourage our computed probability distribution that's come out of this softmax function to match this target probability distribution that has all the mass on the correct class.

我们这么做的方法，可以用多种方式来列这个方程，可以在目标概率分布与计算出的概率分布间计算 KL 散度，以比较他们的差异。可以去做一个最大似然估计，但现在，我们真的想要的是真实类别的概率应该比较高并且接近 1。我们的损失函数就是真实类别概率的对数再取负值。这可能有点难以理解，因为我们是通过多种不同的东西构建出来的，你只需要记住的是我们希望概率趋近于 1，$log​$ 函数是一个单调递增函数，遵循数学上规定的走势，找 $log​$ 函数的最大值相对简单，只要我们使概率最大就可以了，所以我们选择了 $log​$ 函数。由于 $log​$ 函数单调，当我们针对正确类别最大化 $log P​$，意味着我们想要它变高，但是损失函数是用来度量坏的程度，而不是好的程度，所以我们加了一个负号，让它更加符合我们的预设。所以针对正确类别，SVM 的损失函数将会变成 $-log P​$。

And the way we do this, you can do this equation in many ways, you can do this as a KL divergence between the target and the computed probability distribution, you can do this as a maximum likelihood estimate, but at the end of the day, we really want is that the probability of the true class is high and as close to one. So then our loss will now be then negative log of the probability of the true class. This is kind of confusing because we're putting this through multiple different things, but remember we wanted the probability to be close to one, so now log is a monotonic function, and it turns out mathematically, it's easier to maximize log than it is to maximize the raw probability, so we stick with log. And now log is monotonic, so if we maximize $log P​$ of correct class, that means we want that to be high, but loss function measure badness not goodness, so we need to put in the minus one to make it go the right way. So now our loss function for SVM is going to be the minus log of the probability of the true class.

小结一下，我们用 softmax 对分数进行转化处理，并得到正确分类的损失函数是 $-log P$。

Let's summary here, we take our scores, we run through the softmax, and now our loss is this minus log of the probability of the true class.

------

<center>
    <img src=".\images\3.1_11-softmax-example.png">
</center>
------

我们回到猫的例子中，通过线性分类器，我们得到三个分数，这些分数同 SVM 损失函数中的分数是一样的。但是现在我们不直接把这些分数直接放在损失函数里，而是将他们进行指数化处理，因此他们都是正数，然后对他们进行归一化，以保证他们的和是 1。这时损失函数就是 $-log P​$。这就是 softmax，也叫作多项式逻辑斯蒂回归。

We go back to cat example and we've got these three scores that are coming out of our linear classifier, and these scores are exactly the way that they were in the context of the SVM loss. But now rather than taking these scores. and putting them directly into our loss function, we're going to take them all and exponentiate them, so taht they're all positive, and then we'll normalize them to make sure  that they all sum to one. And now our loss will be the minus log of the true class score. That's softmax also called mutinomial logistic regression.

*问题一，softmax 损失函数的最小值和最大值是多少？*

*what's the min and max value of the softmax loss?*

*最小值是 0，最大值是无穷大。对此你可以这么理解，针对正确的类别，我们希望概率是 1，不正确类别的概率是 0，这时我们的方式，如果是这样的话，那么 log 函数里的自变量是 1，因为那是真实类别所对应的概率，1 的对数是 0,1 的对数的负值仍然是 0。这意味着如果我们所有的事情都做对了，我们的损失函数会是 0。但同时，为了保证所有的事情都做对了，我们的分数应该是怎么样的呢？所以会分数实际上必须相当极端，趋于无穷远。因为我们这里进行了指数化，归一化，我们可以得到一个 1 和 0 的概率分布唯一方法就是，为正确分类取一个无穷大的分值，然后为不正确的分类取负无穷大的分值。计算机在无穷方面做得不好，所以在实践中，在精度有限的东西上，不可能得到零损失。还可以这么解释，这里零是理论上的最小损失，而最大的损失是无限的。假设我们正确分类的概率质量函数为 0 （0 值离散概率分布），对其进行求对数之后取负值，0 的对数是负无穷大，那么取负值之后的 0 的对数是无穷大，这很糟糕。再强调一次，你永远不会遇到这种情况，因为你唯一能达到这个概率是 0 的情况是 $e​$ 的正确分类分值次方是 0。而这只有在正确分类分值是负无穷时才发生。所以，你永远不会达到这个有限精度的极值。*

------

The min loss is zero, and the max loss is infinity. And the way you  can see this, the probability distribution that we want is one on the correct class, zero one the incorrect classes, the way we do that is if that were the case, then this thing inside the log would end up being one, because it's the log probability of the true class, then log of one is zero, minus log of one is still zero. So that means that if we got the thing totally right, then our loss would be zero. But by the way, in order to get the thing totally right, what would our scores have to look like? So the scores would actually have to go quite extreme, like towards infinity. So becasue we actually have this exponentiation, this normalization, the only way we can get a probability distribution of one and zero, is actually putting an infinite score for the correct class, and minus infinity score for all the incorrect classes. Computers don't do so well with infinities, so in practice, you'll never get to zero loss on this thing with finite precision. But you'll have this interpretation, that zero is the theoretical minimum loss here. And the maximum loss is unbounded. Suppose we had zero probability mass on the correct class, then you would have minus log of zero, log of zero is minus infinity, so minus log of zero would be plus infinity, so that's really bad. But again, you'll never get here because the only way you can actually get this probability to be zero, is if $e$ to the correct class score is zero, and that can only happen if that correct class score is minus infinity. So again, you'll never get to these minimum, maximum values with finite precision.*

*记住我们有这个纠错机制，在多类支持向量机的背景下的健全性检查问题，我们可以问 softmax。如果所有的 S 都很小，近乎为 0，损失之是多少？*

*So then, remember we had this debugging, sanity check question in the context of the multi-class SVM, we can ask the same for the softmax. If all the Ss are small and about zero, then what is the loss here?*

*$log(c)$。这是一个很好的纠错机制，如果你正在用这个 softmax 损失来训练一个模型，你应该在第一次迭代中检查，如果它不是 $C$ 取自然对数，那么就出了问题。（相当于 0 向量每个元素做指数运算，得到全是 1 的向量，然后归一化之后得到全是 $1/C$ 的向量，损失自然就是 $-log(1/c)$，也就是 $log(C)$ ）*

*It's just log of C. This is a nice debugging thing, if you're training a model with this softmax loss, you should check at the first iteration. If it's not log C, then something's gone wrong.*

------

<center>
    <img src=".\images\3.1_12-contrast-SVM-softmax.png">
</center>
------

对比一下这两个损失函数，在线性分类方面，我们将 $W​$ 和输入向量相乘，得到分值向量，那么两个损失函数的区别是如何解释这些分值进而定量度量到底有多坏。对于 SVM 深入研究和观察，正确的分类的分值和不正确分类的分值的边际，而对于这个 softmax 或交叉熵损失，我们打算去计算一个概率分布，然后查看正确分类的负对数概率。

So then we can compare and contrast these two loss functions a bit, in terms of linear classification, this setup looks the same, we've got this $W$ matrix that gets multiplied against our input to produce this specter of socres, and now the difference between the two loss functions is how we choose to interpret those scores to quantitatively measure the badness afterwards. So for SVM, we were going to go in and look at the margins between the scores of the correct class and the scores of the incorrect class whereas for this softmax or cross-entropy loss, we're going to go and compute a probability distribution, and then look at the minus log probability of the correct class.

回到在多分类 SVM 损失函数中车的例子，当样本中有车，那么车的分值就会比其他不正确的分类的分值要高，即使车的分值稍微有些变化，也并不会对结果产生根本改变。因为 SVM 损失函数来说，唯一关心的是正确的分值要比不正确的分值高出一个安全边际。但是 softmax 这种方式就相当不同了。softmax 的目标是将概率质量函数（离散分布值）等于 1。所以，你给正确分类再高的分值，同时给不正确分类再低的值，softmax 依然会在正确分类上积累更多的概率质量，争取的分类向无穷大迈进，并持续将这一分值推向无穷大，不正确分类的分值推向负无穷。SVM 会得到这个数据点超过阈值，要正确分类，然后放弃，它不再关心那个数据点了。而 softmax 只是总是试图不断提高每一个数据点都会越来越好。在实践中，选择哪个并不会造成巨大的影响，在很多深度学习应用中，他们倾向于表现相似，但是知道这些差异是非常有用的。

If we go back to this example where in the multi-class SVM loss when we had the car, and the car score was much better than all the incorrect classes, then jiggling the scores for that car image, didn't change the multi-class SVM loss at all, because the only thing that the SVM loss cared about was getting that correct score to be greater than a margin above the incorrect scores. But the softmax loss is quite different in this respect. The softmax loss always wants to drive that probability mass all the way to one. So even if you're giving very high score to the correct class, and very low score to all the incorrect classes, softmax will want you to pile more and more probability mass on the correct class, and continue to push the score of that correct class up towards infinity, and the score of the incorrect classes down towards minus infinity. SVM, it'll get this data point over the bar to be correctly classified and then just give up, it doesn't care about that point any more. Whereas softmax will just always try to continually imporve every single data point to get better and better. In practice, I think it tends not to make a huge difference which one you choose, they tend to perform pretty similarly across at least a lot of deep learning applications. But it is very useful to keep some of these differences in mind.

## 3.1.7 回顾 Recap

------

<center>
    <img src=".\images\3.1_13-recap-loss-function.png">
</center>
------

我们有训练数据，然后用线性分类器根据我们的输入 $x$ 来及算分数 $S$，然后用损失函数，可以是 softmax 或者 SVM 或者其他损失函数，来定量计算我们的预算和真实目标偏离有多大。通常会在损失函数上加上一个正则化的部分，试图在训练数据之间进行权衡并偏向于更简单的模型。这是监督学习中非常通用的描述，随着学习的深入，我们将在深度学习中看到，通常要指定一些函数 $f$，这在结构上可能非常复杂，指定损失函数决定算法，给出一些参数，正则化项来惩罚模型复杂度，然后把这些结合起来，来找到 $W$，使损失函数最小。

We have got some xs and ys, we use our linear classifier to get some score function, to compute our scores S, from out inputs, $x$, and then we'll use a loss function, maybe softmax or SVM or some other loss function, to compute how quantitatively bad were our predictions compared to this ground true targets, $y$. And then we'll often this loss function with a regularization term, that tries to trade off between fitting the training data and preferring simpler models. So this is a pretty generic overview of a lot of what we call supervised learning, and we'll see in deep learning as we move forward, is that generally you'll want to specify some function, f, that could be very complex in structure, specify some loss function that determines how well your algorithm is doing,  given any value of the parameters, some regularization term for how to penalize model complexity, and then you combine these things together and try to find $W$ that minimizes this final loss function.

但问题是我们怎么去做这件事。如何才能真正发现这个 $W$ 使损失最小化？接下来就是优化的部分。

But then the question is, how do we go about doing that? How do we find this $W$ that minimizes the loss? And that leads us to the topic of optimization.