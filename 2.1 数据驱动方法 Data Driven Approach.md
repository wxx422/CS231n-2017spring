# 2.1 图像分类 数据驱动方法 Image Classification pipeline

##  2.1.1 介绍 Introduction

我们上一节课介绍了图像分类的任务，这是计算机视觉中真正核心的任务。更具体地说，当你做图像分类时，分类系统接收一些输入图像，比如猫，并且系统清楚了一些已经确定了分类或者标签的集合，可能是狗、猫、卡车、飞机。还有一些固定的类别标签集合，那计算机的工作就是看图片并且给他分配其中一个固定的分类标签。

Last lecture we talked about this task of image classification, which is really a core task in computer vision. So, more concretely, when you're doing image classification, your system receives some input image, which is this cute cat in this example, and the system is aware of some predetermined set of categories or labels, like, a dog or a cat or a truck or a plane, and there's some fixed set of category labels, and the job of the computer is to look at the picture and assign it one of these fixed category labels.

这听起来是个非常简单的问题，因为大脑里的视觉系统天生就是来做这些视觉识别任务的。但是对于机器来说，这是一个那题。如果你深入思考，当一个计算机看着这些图片的时候，它看到的是什么。不像人看到图片一样，它肯定没有猫的整体概念。

This seems like a really easy problem, because so much of your own visual system in your brain is hardwired to doing these, sort of visual recognition tasks. But this is a really really hard problem for a machine. So, if you dig in and think about, what does a computer see when it looks at this image, it definitely doesn't get this holistic idea of a cat that you see when you look at it. 

------

<center>
    <image src="./images/2.1_01_cat.png">
</center>
------

计算机呈现图片的方式其实就是一大堆数字。图像可能是一些 800 * 600 像素的。每一个像素点由三个数字表示，给出像素红、绿、蓝三个值。对于计算机来说，这就是一个巨大的数字阵列。很难从上千各不同的数字中提取猫咪的特性。我们把这个问题称为**语义鸿沟**。对于猫的概念或者它的标签，是我们赋予图像的一个语义标签，在语义概念和计算机看到的像素值之间存在鸿沟。

Computer really is representing the image as this gigantic grid of numbers. So, the image might be something like 800 by 600 pixels. And each pixel is represented by three numbers, giving the red, green, and blue values for that pixel. To the computer, this is just a gigantic grid of numbers. And it's very difficult to distill the cat-ness out of this giant array of thousands, or whatever, very much different numbers. We refer to this problem as the **semantic gap**. This idea of a cat, or this label of a cat, is a semantic label that we're assigning to this image, and there's this huge gap between the semantic idea of a cat and these pixel values that the computer is seeing.

另一个很难的问题是你可以用很微小、微妙的方式改变图片并导致像素网格整个发生变化。同样还是这只猫，并且猫坐着不动，但是我们把相机移动到另一边，那么这个巨大数字网格中的每一个小格子，每一个像素都会完全不同。但它同样代表这只猫。所以我们的算法需要对这些变化鲁棒。但是，不仅仅只有**视角**这一问题，还有**照明**问题。在场景中会有不同的照明条件。无论猫出现在漆黑、昏暗的场景中，还是明亮、阳光照射的场景中，它始终都是猫。算法需要对这些鲁棒。目标对象有时还会**变形**。我认为猫在动物中就是比较会变形的，而且猫可以有千奇百怪的姿势和位置。对于不同的形变情况，我们的算法也应该是鲁棒的。当然也可能有**遮挡**的问题，可能只能看到猫的部分，比如猫脸，甚至只能看到尾巴尖从沙发垫下露出。作为人类，在上述情况中，你非常容易意识到这是猫，仍把这些图像看作猫。这也是我们的算法需要鲁棒应对的一种情况，这是一件很难的事情。处理的时候还会有图片**背景混乱**的问题，比如可能一张图片的前面显示是一只猫，可能猫身上的纹理，和图片背景很相似。这就是我们需要处理的另一个问题。还有可能会有**类内差异**，这张图看上去是一些猫，但实际上每只猫都会有视觉上的差异。比如猫有不同的外形、大小、颜色及年龄。算法需要处理这些不同。

And this is a very hard problem because you can change the picture in very small, subtle ways that will cause this pixel grid to change entirely. For example, if we took this same cat, and if the cat happened to sit still and not even twitch, not move a muscle, but we moved the camera to the other side, then every single grid, every single pixel, in this giant grid of numbers would be completely different. But somehow, it's still representing the same cat. And our algorithms need to be robust to this. But not only **viewpoint** is one problem, another is **illumination**. There can be different lighting conditions going on in the scene. Whether the cat is appearing in this very dark, moody scene, or very bright, sunlit scene, it's still a cat. Our algorithms need to be robust to that. Objects  can also **deform**. Cats are, among the more deformable of animals that you might see out there. And cats can really assume a lot of different, varied poses and positions. And our algorithms should be robust to these different kinds of transforms. There can also be problems of **occlusion**, where you might only see part of a cat, just the face, or in this extreme example, just a tail peeking out from under the couch cushion. But, in these cases, it's pretty easy for you, as a person, to realize that this is probably a cat, and you still recognize these images as cats. And this is something that our algorithm also must be robust to, which is quite difficult. There can also be problems of **background clutter**, where maybe the foreground object of the cat, could look quite similar in appearance to the background. And this is another thing that we need to handle. There is also this problem of **intraclass variation**, that this one notion of cat-ness, actually spans a lot of different visual appearances. And cats can come in different shapes and sizes and colors and ages. And our algorithm needs to work and handle all these different variations.

这是一个挑战性的难题，但是在大脑处理这些的时候不觉得有什么难的。因为大脑里早就有处理这些东西的神经存在。但是现在，我们想让计算机程序，同时来处理这些事情，且不说猫的图片，任何你能想象到的物体，都会是很难的算法问题。尽管这些问题很难处理，但是奇迹的是，目前已经有有效的算法可以来处理这些事情。这些算法不仅有效，而且在某些特定的情况下接近人脑处理，这些算法只用几百毫秒的时间。这是难以置信的技术，我们将会看到都有哪些先进手段让这一切成为可能。

So this is actually a really really challenging problem, and it's sort of easy to forget how easy this is because so much of your brain is specifically tuned for dealing with these things. But now if we want computer programs to deal with all of these problems, all simultaneously, and not just for cats, by the way, but for just about any object category you can imagine, this is a fantastically challenging problem. And it's actually, somewhat miraculous that this works at all. Actually, not only does it work, but these things work very close to human accuracy in some limited situations, and take only hundreds of milliseconds to do so. So, this is some pretty amazing, incredible technology, and we will see what kind of advancements have made this possible.

如果你现在在想对于图像分类有哪些程序调用接口，你可能要写一个 python 方法，接受一个图片作为参数，然后来一波操作，最后得出分类标签。并没有什么直截了当的算法可以解决图像识别算法。如果你在上算法课，你的任务是排序或者计算凸包，再或者比如信息隐藏加密技术的一些算法。你可以写一个算法枚举所有可能发生的步骤来完成这些任务。但是我们来解决识别对象的算法的时候，识别猫啊图片啊，并没有什么简洁明了的算法可以直接完成这些识别。

So now, if you think about what is the API for writing an image classifier, you might sit down and try to write a method in Python like this, where you want to take in an image and then do some crazy magic, eventually, spit out this class label. And there is really no obvious way to do this. If you are taking an algorithms class, and your task is to sort numbers or compute a convex hull, or even do something like RSA encryption. You can write down an algorithms and enumerate all the steps that need to happen in order for this things to work. But when we're trying to recognize objects, or recognize cats or images, there is no really clear, explicit algorithm that makes intuitive sense for how you might go about recognizing these object. 

## 2.1.2 数据驱动方法 Data-driven approach

尽管如此，人们还是做了很多尝试，尝试写出一组硬编码的规则来识别不同的动物。我们知道猫有耳朵、眼睛、嘴巴、鼻子。根据 Hubel 和 Wiesel 的研究，我们了解到边缘对于视觉识别是十分重要的。所以我们可以尝试计算出图像的边缘，然后把边、角各种形状分类好。比如有三条线相交，那这就可能是一个角。比如猫耳朵有这样那样的角，诸如此类，我们可以写一些规则来识别这些猫。但是实际上这种算法并不好。首先很容易出错，其次，如果我们想对另一种对象进行分类，比如卡车、狗、鱼等等，就需要从头再来一遍。这不是一种可拓展的方法。我们想发明一些识别算法，可以拓展到识别世界上各种对象。

That being said, people have definitely made explicit attempts to try to write, sort of, high-end codes rules for recognizing different animals. We know cats have ears and eyes and mouths and noses. And we know that edges, from Hubel and Wiesel, are pretty important when it comes to visual recognition. So one thing we might try to do is compute the edges of this image and then go in and try to categorize all the different corners and boundaries. Say that, if we have three lines meeting this way, then it might be a corner, and a ear has one corner here and one corner there, and then, write down this explicit set of rules for recognizing cats. But this turns out not to work very well. One, it's super brittle, and two, if you want to start over for another object category, and maybe not worry about cats, but talk about trucks or dogs or fishes or something else, then you need to start all over again. This is really not a very scalable approach. We want to come up with some algorithms, or some method for these recognition tasks which scales much more naturally to all the variety of objects in the world.

基于此，我们想到用数据驱动的方法。我们不写具体的分类规则来识别猫或者鱼，取而代之的是，我们从网上抓取数据大量的猫、飞机、鹿等的图片数据集。一旦有了数据集，我们训练机器来分类这些图片，机器会收集所有数据，用某种方式总结，然后生成一个模型。总结出识别这些不同类的对象的核心知识要素。然后我们用这些模型识别新的图片，看能不能识别狗猫等。

So, the insight that, makes this all work is this idea of the data-driven approach. Rather than writing these hand-specified rules to try to craft exactly what is a cat or a fish or what have you, instead, we'll go out onto the internet and collect a large dataset of many cats, airplanes, deer, and different things like this. Once we get this dataset, we train this machine learning classifier that is going to ingest all of the data, summarize it in some way, and then spit out a model that summarizes the knowledge of how to recognize these different object categories. Then finally, we'll use this training model and apply it on new images that will then be able to recognize cats and dogs and what not.

------

<center>
    <image src="./images/2.1_02_data-driven.png">
</center>
------

所以我们的接口变成这样，不仅仅是输入图片，然后识别它是一只猫，我们会有两个函数，一个是训练函数，这函数接收图片和标签，然后输出模型，另一种是预测函数，接收一个模型，对图片分类。正是用了这种方法，在过去十几二十年间，图像识别领域的进步非常大。

So our API has changed a little bit. Rather than a single function, that just inputs an image and recognizes a cat, we have these two functions. One, called, train, that's going to input images and labels and then output a model, and then, separately, another function called, predict, which will input the model and then make predictions for images. And this is the key insight that allowed all these things to start working really well over the last 10, 20 years or so.

本系列课程主要讨论神经网络、卷积神经网络和深度学习等。但是这种数据驱动类的算法是比深度学习更广义的一种理念，这种理念十分有用。通过这种过程，对于提炼一个简单的分类器非常有用。

This class is primarily about neural networks and convolutional neural networks and deep learning and all that. But this idea of a data-driven approach is much more general than just deep learning, and I think it's useful to, step through this process, provides simple classifier first.

## 2.1.3 最近邻分类 Nearest Neighbor

最简单的分类器，我们称为最近邻。在训练过程中，我们什么也不做，只是简单记录所有的训练数据。在预测阶段，我们会拿一些新的图片在训练数据中寻找与新图片最相似的，然后基于此，给出一个标签。非常简单的算法，但是这里很多用到的属性都是数据驱动的。

The simplest classifier you can imagine is something we call nearest neighbor. During the training step, we won't do anything, we'll just memorize all of the training data. During the prediction step, we're going to take some new image and go and try to find the most similar image in the training data to that new image, and now predict the label of that most similar image. A very simple algorithm, but it has a lot of these nice properties with respect to data-drivenness and what not.

具体来说，比如 CIFAR-10 的数据集，这是在机器学习中很常用的一个测试数据集，这个数据集给出 10 个不同的类别，飞机、汽车、鸟、猫等。给出 5 万张训练数据图，大体上平均分布在这 10 个类别中个。还会有 1 万张额外的测试图片，来测试你的算法。

So, to be more concrete, you might imagine working on this dataset called CIFAR-10, which is very commonly used in machine learning, as kind of a small test case. This dataset gives you 10 different classes, airplanes and automobiles and birds and cats and different things like that. It provides 50,000 training images, roughly evenly distributed across these 10 categories. And then 10,000 additional testing images that you're supposed to test your algorithm on.

------

<center>
    <image src="./images/2.1_03_nearest-neighbor-CIFAR-10.png">
</center>
------

举个例子，这是在 CIFAR-10 数据集上的最近邻分类器。在右边最左边的一列，是 CIFAR-10 数据集的测试图片，我们训练图片进行分类，并显示对应测试示例的最相似的训练图片。可以看到虽然不完全正确，但看起来还是非常相似。

Here's an example of applying this simple nearest neighbor classifier to some of these test images on CIFAR-10. On this grid on the right, for the left most column, gives a test image in the CIFAR-10 dataset. And now on the right, we've sorted the training images and show the most similar training images to each of these test examples. And you can see that they look kind of visually similar to the training images, although they are not always correct.

我们看测试图片的第二行，测试图片是狗，最相似的图片也是狗，但是接下来我想是鹿或者马或者别的东西。他们看起来非常相似，中间都是白的一团。所以当我们将最近邻算法用于这些图片，我们就能在训练集中找到最接近的示例样本，因为它来自训练集，我们知道这些最接近示例的标签。这时我们可以简单地说，这幅测试图片也是一只狗。你可以看到这些示例也许分类得不好，但它仍然是一个好的示例。

On the second row, we see that the testing image is a dog and it's nearest neighbor is also a dog, but this next one, I think is actually a deer or a horse or something else. But, you can see that it looks quite visually similar, because there is kind of a white blob in the middle. So if we're applying the nearest neighbor algorithm to these images, we'll find the closest example in the training set. And now, the closest example, we know it's label, because it comes from the training set. And now, we'll simply say that this testing image is also a dog. You can see kind from these examples that is probably not going to work very well, but it's still kind of a nice example to work through.

------

<center>
    <image src="./images/2.1_04_L1-distance.png"></image>
</center>
------

我们需要知道一个细节，给出两张图片，我们该怎样对他们进行比较？如果我们要将测试图片与所有训练图片进行比较，我们将有很多不同选择，来确定需要什么样的比较函数。在上一张幻灯片的示例中，我们使用了 $L1​$ 距离，有时我们称之为曼哈顿距离。这是一个简单易行的比较图片的方法。我们只是对这些图片中的像素进行比较。假设我们的测试图片只是 4*4 的小图片，我们只取测试图像，用它减去训练图像对应像素的值，取绝对值，得到这两幅图像这个像素的差别，将图像中所有像素差值相加。虽然这种比较图片的方法看起来有点笨，但有时也有他的合理性。它也给了我们一个比较两幅图片的具体方法。在这个例子的两幅图像中，共有 456 处不同。

But then, one detail that we need to know is, given a pair of images, how can we actually compare them? Because, if we're going to take our test image and compare it to all the training images, we actually have many different choices for exactly what that comparison function should look like. In the example in the previous slide, we've used what's called the $L1$ distance, also sometimes called the Manhattan distance. It's a really simple, easy idea for comparing images. And that's that we're going to just compare individual pixels in these images. Supposing that our test image is maybe just a tiny four by four of pixel values, then we're taking this upper-left hand pixel subtract off the value in the training image, take the absolute value, and get the difference in that pixel between the two images. And then, sum all these up across all the pixels in the image. So, this is kind of a stupid way to compare images, but it does some reasonable things sometimes. This gives us a concrete way to measure the difference between two images. And in this case, we have this difference of 456 between these two images.

------

```python
import numpy as np
class NearestNeighbor:
    def __init__(self):
        pass
    def train(self, X, y):
        """ X is N x D where each row is an example. Y is 1-dimension of size N """
        self.Xtr = X
        self.ytr = y
	def predict(self, X):
        """ X is N x D where each row is an example we wish to predict label for"""
        num_test = X.shape[0]
        # lets make sure that the output type matches the input type
        Ypred = np.zeros(num_test, dtype = self.ytr.dtype)
        
        #loop over all test rows
        for i in xrange(num_test):
            #find the nearest training image to the i'th test image
            #using the L1 distance (sum of absolute value differences)
            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
            #get the index with smallest distance
            min_index = np.argmin(distances) 
            #predict the label of the nearest example
            Ypred[i] = self.ytr[min_index]
		return Ypred
```

------

这是最近邻分类器的完整 Python 代码，因为我们使用了 Numpy 提供的向量运算，它非常简明。

Here's some full Python code for implementing this nearest neighbor classifier, it's pretty short and pretty concise because we've made use of many of these vectorized operations offered by Numpy.

这里还有一些关于简单分类器的问题。问题一，如果我们在训练集中有 $N​$ 个实例，训练和测试的过程可以有多快？

A couple questions about this simple classifier. Question one ,if we have $N$ examples in our training set, then how fast can we expect training and testing to be?

$O(1)​$ 和 $O(N)​$。当然，训练是连续的过程，因为我们并不需要做任何事情，只需要存储数据。如果你只是复制一个指针，无论你的数据集多大，这是一个恒定的时间。但在测试时，我们需要停下来，将数据集中 $N​$ 个训练实例与我们的测试图像进行比较。这个过程很慢。你会发现这个过程非常落后。因为在实际使用中，我们希望训练过程比较慢，而测试过程很快。因为训练过程可能是在数据中心完成的，它可以负担起非常大的运算量，从而训练出一个优秀的分类器。当你在测试过程部署分类器时，你希望它运行在手机上，或者浏览器或者其他低功耗设备。但你又希望分类器能够快速运行。由此看来，最近邻算法有点落后。我们再看看卷积神经网络和其他参数模型则正好相反。它们会花很多时间在训练上，而在测试过程则非常快。

$O(1)$ and $O(N)$. Well, training is probably constant, because we don't really need to do anything, just need to memorize the data. And if you're just copying a pointer, that's going to be constant time, no matter how big your dataset is. But now, at test time we need to do this comparison stop and compare our test image to each of the $N$ training examples in the dataset. And this is actually quite slow. So this is somewhat backwards if you think about it. Because in practice, we want our classifiers to be slow at training time and then fast at testing time. Because that a classifier might go and be trained in a data center somewhere and you can afford to spend a lot of computation at training time to make the classifier really good. But then, when you go and deploy the classifier at test time, you want it to run on your mobile phone or in a browser or some other low power device,  and you really want the testing time performance of your classifier to be quite fast. So, from this perspective, this nearest neighbor algorithm, is actually a little backwards. And we'll see that once we move to convolutional neural networks, and other types of parametric models, they'll be the reverse of this. Where you'll spend a lot of compute at training time, but then they'll be quite fast at testing time.

那么问题来了，在实际应用中，最近邻算法表现如何？

So the question comes, what exactly does this nearest neighbor algorithm look like when you apply it in practice?

------

<center>
    <image src="./images/2.1_05_K-nearest-neighbor.png"></image>
</center>
------

我们画了这图形，我们叫它最近邻分类器的决策区域。我们的训练集包含二维平面中的这些点，点的颜色代表不同的类别，或不同的类标签。我们看到这里有五个类别，上面角落里有蓝色的点，对整幅图像的每个点来说，我们将计算这些训练数据中最近的实例，然后在这些点的背景上着色，标出它的类标签。你可以发现最近邻分类器是根据相邻的点，来切割空间并进行着色。但这个分类器并非是个好的选择。观察这张图片，你会发现最近邻分类器的一些问题。其中一个就是图像的中部集中了大多数的绿点，但中心却又一个黄点，因为我们只计算最近的点，所以在绿色区域的中间这个黄点被分割成了独立一块。这并不好，也许那些点事实上应该是绿色。还有因为一个绿点，绿色区域像一根手指一样插入了蓝色区域，而这个点可能是噪音或者失真信号。

So we've drawn, what we call the decision regions of a nearest neighbor classifier. Here our training set consists of these points in the two dimensional plane, where the color of the point represents the category, or the class label, of that point. We see we have five classes and some blue ones up in the corner here, and for each pixel in this entire plane, we've gone and compute what is the nearest example in the training data, and then colored the point of the background corresponding to what is the class label. So you can see that this nearest neighbor classifier is just sort of carving up the space and coloring the space according to the nearby points. But this classifier is maybe not so great. By looking at this picture, you can start to see some of the problems that might come out with a nearest neighbor classifier. For one, this central region actually contains mostly green points, but one little yellow point in the middle, because we're just looking at the nearest neighbor, this causes a little yellow island to appear in this middle of this green cluster. And that's not so great, maybe those points actually should have been green. And then, similarly we also see these, sort of, fingers, like the green region pushing into the blue region, which may have been noisy or spurious.

## 2.1.4 k-最近邻分类 k-Nearest Neighbor Classify

由这个动机出发，产生了 K-最近邻 算法，它不只是寻找最近的点，我们会做一些特殊的操作，根据我们的距离度量，找到最近的 K 个点，然后在这些相邻点中进行投票预测出结果。你可以想象一下更复杂地完成这个任务的方法，你也可以在距离上加权再进行投票等等，但完成这个任务最简单的方法还是进行多数投票。我们这里用同样的数据集使用 K = 1 的最近邻分类器，在中间和右边使得 K 等于 3 和 5。

This kind of motivates a slight generalization of this algorithm called k-nearest neighbors. So rather than just looking for the single nearest neighbor, instead we'll do something a little fancier and find K of our nearest neighbors, according to our distance metric, and then take a vote among each of our neighbors, and then predict the majority vote among our neighbors. You can imagine slightly more complex ways of doing this, maybe you'd vote weighted on the distance or something like that, but the simplest thing that tends to work pretty well is just taking a majority vote. Here we've shown the exact same set of points using this K = 1 nearest neighbor classifier, as well as K = 3 and K = 5 in the middle and on the right.

在 K 等于 3 时我们看到绿色点簇中的黄色噪点不会再导致周围的区域被划分为黄色。由于使用多数投票，中间的整个绿色区域都被分类为绿色。而伸入红色和蓝色区域的这些细栅线，也开始被平滑掉。而在 K = 5 时，蓝色和红色区域间的这些决策边界变得更加平滑好看。所以当你使用最近邻分类器时，你总会给 K 赋一个比较大的值，这样会使决策边界更加平滑从而得到更好的结果。

And once we move to K = 3, you can see that that spurious yellow point in the middle of the green cluster is no longer causing the points neat that region to be classified as yellow. Now this entire green portion in the middle is all being classified as green. You can also see that these fingers of the red and blue regions are starting to get smoothed out due to this majority voting. And then, once we move the K = 5 case, then these decision boundaries between the blue and red regions have become quite smooth and quite nice. So generally when you're using nearest neighbors classifier, you almost always want to use some value of K, which is larger than one, because this tends to smooth out your decision boundaries and lead to better results.

白色区域代表什么？

What is the deal with these white regions?

白色区域表示这个区域中没有获得 k-最近邻 的投票。你可以做一个大胆的假设，将它归为某一个类别。但在这个简单例子中，我们将它标为白色，表示在这个区域没有最近的其他点。

The white regions are where there was no majority among the k-nearest neighbors. You could imagine doing something slightly fancier, and maybe taking a guess or randomly selecting among the majority winners. For this simple example, we're just coloring it white, to indicate there was no nearest neighbor in those points.

当我们在思考计算机视觉时，我认为在几种不同的观点之间反复思考与验证非常有用。第一种观点，在平面上的高维点概念，另一个观点就是具体图像的观察。因为图像的像素允许我们把这些图像看做高维向量。在两种不同的观点之间反复切换思考是非常有用的。

Whenever we're thinking about computer vision, I think it's really useful to kind of flip back and forth between several different viewpoints. One is this idea of high dimensional points in the plane, and then the other is actually looking at concrete images. Because the pixels of the image allow us to think of these images as high dimensional vectors. And it's sort of useful to ping pong back and forth between these two different viewpoints.





