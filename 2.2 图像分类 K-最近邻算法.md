# 2.2 图像分类 K-最近邻算法 K-Nearest Neighbor Algorithm

##  2.2.1 距离度量 Distance Metric

接下来我们讨论 KNN 回到图片上，可以看到，它实际上表现不是很好。这里我标记了红色和绿色，图片分类的正确与否取决于它的最近邻值。但如果我们使用一个更大的 K 值，那么投票操作的结果就可能会达到前三名或者前五名，甚至包括到所有的数据范围。可以想象到当我们用这种方法来检索相邻数据时，这样会对噪声产生更大的鲁棒性。

So then, sort of taking this K-nearest neighbor and going back to the images, you can see that it's actually not very good. Here I've colored in red and green which images would actually be classified correctly or incorrectly according to their nearest neighbor. And you can see that it's really not very good. But if we used a larger value of K, then this would involve voting among maybe the top three or top five or maybe even the whole row. And you can imagine that would end up being a lot robust to some of this noise that we see when retrieving neighbors in this way.

------

<center>
    <image src="./images/2.2_01_L1-L2-distance.png"></image>
</center>
------

另一个选择就是当我们使用 k-最近邻 算法时，确定我们应该如何比较相对近邻数据距离值。我们已经展示了 L1 距离，它是像素之间差值绝对值的总和。另一种常见的选择是 L2 距离，也就是欧氏距离，即：取平方和的平方根，并把这个作为距离。

Another choice we have when we're working with the k-nearest neighbor algorithm is determining exactly how we should be comparing our different points. For the examples so far we've just shown, we've talked about this L1 distance which takes the sum of the absolute values between the pixels. Another common choice is the L2 or Euclidean distance where you take the square root of the sum of the squares and take this as your distance.

选择不同的距离度量实际上是一个非常有趣的话题，因为不同的距离度量，会在你的预测空间里，对底层的几何或拓扑结构做出不同的假设。相对于下面所示的 L1 距离，L2 距离实际上是一个根据 L1 距离的这个围绕着圆点的方形形成的圆形。这个方形上的每一个点，在 L1 上是与圆点等距的，而在 L2 或者欧式距离上，类似的会是一个圆，它看起来是你所期望的。特别指出这两种方式之间，L1 距离取决于你所选择的坐标系统。如果转动坐标轴，将会改变点之间的 L1 距离。而改变坐标轴对 L2 距离没有影响，无论在什么样的坐标轴下，L2 距离是确定的。输入的特征向量中，如果向量中的一些值，对任务而言有重要意义，那么 L1 可能更合适。但如果它只是某个空间中的一个通用向量，而你不知道其中的不同元素实际上代表的含义，那么  L2 会更自然一些。

Choosing different distance metrics actually is a pretty interesting topic because different distance metrics make different assumptions about the underlying geometry or topology that you'd expect in the space. So this L1 distance, underneath this, is actually a circle according to the L1 distance and it forms this square shape thing around the origin. Where each of the points on this, on the square, is equal distant from the origin according to L1, where as with the L2 or Euclidean distance, then this circle is a familiar circle, it looks like what you'd expect. So one interesting thing to point out between these two metric in particular, is that the L1 distance depends on your choice of coordinates system. So if you were to rotate the coordinate frame that would actually change the L1 distance between the points. Whereas changing the coordinate frame in the L2 distance doesn't matter, it's the same thing no matter what your coordinate frame is. If your input features, if the individual entries in your vector have some important meaning for your task, then maybe somehow L1 might be a more natural fit. But if it's just a generic vector in some space and you don't know which of the different elements, you don't know what they actually mean, then maybe L2 is slightly more natural.

还有一点是通过使用不同的距离度量，我们可以将 k-最近邻 分类器泛化到许多不同的数据类型上，而不仅仅是向量、图像。假设你相对文本进行分类，那么你唯一需要做的就是对 KNN 指定一个距离函数，这个函数可以测量两段话或两句话，或者类似的东西之间的距离。因此，简单地通过指定不同的距离度量，我们可以在基本上任何类型的数据上很好地应用这个算法。尽管这是一种简单的算法，但总的来说，当你研究一个新问题时，首先尝试它是件好事。

And another point here is that by using different distance metrics, we can generalize the k-nearest neighbor  classifier to many many different types of data, not just vectors, not just images. For example, imagine you wanted to classify pieces of text, then the only thing you need to do to use k-nearest neighbors is to specify some distance function that can measure distance between two paragraphs or two sentences or something like that. So simply by specifying different distance metrics we can apply this algorithm very generally to basically any type of data. Even though it's a kind of simple algorithm, in general, it's a very good thing to try first when you're looking at a new problem.

------



<center>
    <image src="./images/2.2_02_L1-L2-distance2.png"></image>
</center>
------

当我们选择一种不同的距离度量时，几何上发生了什么？我们在左边可以看到，L1 距离或曼哈顿距离，右边使用的是 L2 距离，也叫欧式距离。可以看到在两个度量之间，这些决策边界的形状实际上变化很大。当你看 L1 时，这些决策边界趋向于跟随坐标轴，这是因为 L1 取决于我们对坐标系统的选择。而 L2 对距离的排序并不会受到坐标轴的影响，它只是把边界放置在存在最自然的地方。

It's also kind of interesting to think about what is actually happening geometrically if we choose different distance metrics. Here we see the same set of points on the left, using the L1, or Manhattan distance, on the right, using the familiar L2, or Euclidean distance. You can see that the shapes of these decision boundaries change quite a bit between the two metrics. When you're looking at L1 these decision boundaries tend to follow the coordinate axes. And this is again because the L1 depends on our choice of coordinate system. Where the L2 sort of doesn't really care about the coordinate axis, it just puts the boundaries where the should fall naturally.

## 2.2.2 超参数 Hyper parameters

一旦真的尝试在实践中使用这个算法，有几个选择是你需要做的。我们讨论过选择 K 的不同值，讨论过选择不同的距离度量。你该如何根据你的问题和数据，来选择这些超参数。

Once you're trying to use this algorithm in practice, there's several choices you need to make. We talked about choosing different values of K, choosing different distance metrics. How do you make these choices for your problem and for your data?

像 K 和距离度量这样的选择，我们称之为超参数，因为他们不一定都能从训练数据中学到。你要提前为算法选择超参数。问题在于在实践中，该如何设置这些超参数。这些参数被证明是依赖于具体问题的。多数人只是简单地尝试多种超参数的值，并找出一个最好的。即使是尝试不同的超参数，看看那种表现更好，也会有很多选择。那么尝试不同超参数看哪种更合适，究竟该怎么做呢？

These choices, of things like K and the distance metric, we call hyper parameters, because they are not necessarily learned from the training data, instead these are choices about your algorithm that you make ahead of time and there's no way to learn them directly from the data. The question is how do you set these things in practice? And they turn out to be very problem-dependent. And the simple thing that most people do is simply try different values of hyper parameters for your data and problem, and figure out which one works best. Even this idea of trying out different values of hyper parameters and seeing what works best, there are many different choices here. What exactly does it mean to try hyper parameters and see what works best?

你首先会想到的一点可能是选择对训练集给出最高准确率、表现最佳的超参数。这其实是一种非常糟糕的想法，千万不要这么做。例如，在之前的 K-最近邻 分类算法中，假设 K = 1, 我们总能完美地把训练集进行分类。所以如果我们采用这一策略总是选择 K = 1，但是正如之前案例所见的，在实践中让 K 取更大的值，尽管在训练集中分错个别数据，但对于在训练集中未出现过的数据分类性能更佳。归根到底在机器学习中，我们关心的不是要尽可能拟合训练集，而是要让我们的分类器，在训练集以外的未知数据上表现更好。

The first idea you might think of is simply choosing the hyper parameters that give you the best accuracy or best performance on your training data. This is actually a really terrible idea. You should never do this. In the concrete case of the nearest neighbor classifier, for example, if we set K = 1, we will always classify the training data perfectly. So if we use this strategy we'll always pick K = 1, but, as we saw from the examples earlier, in practice it seems that setting K equals to larger values might cause us to misclassify some of the training data, but, in fact, lead to better performance on points that were not in the training data. And ultimately in machine learning we don't care about fitting the training data, we really care about how our classifier will performance on unseen data after training. 

大家可能会有的另一个想法就是把所有的数据分成两部分，一部分是训练集，另一部分是测试集。然后在训练集上用不同的超参数来训练算法，然后将训练好的分类器用在测试集上，再选一组在测试集上表现最好的超参数。这看起来似乎是个合理的策略，但实际上也非常糟糕，千万别这么做。因为机器学习的目的是让我们了解算法表现究竟如何。所以测试集的目的是给我们一种预估方法，即在没遇到的数据上算法表现将会如何。如果采用这种够用不同的超参数训练不同算法的策略，然后选择在测试集上表现最好的超参数。那么很可能我们选择了一组超参数，只是让我们的算法在这组测试集上表现良好，但这组测试集的表现无法代表在全新的未见过的数据上的表现。再说一遍，不要怎么做，这个想法也很糟糕，如果这么做，肯定会遇到麻烦。

Another idea that you might think of, is we'll take our full dataset and we'll split it into some training data and some test data. And now I'll try training my algorithm with different choices of hyper parameters on the training data and then I'll go and apply that trained classifier on the test data and now I will pick the set of hyper parameters that cause me to perform best on the test data. This seems like maybe a more reasonable strategy, but, in face, this is also a terrible idea and you should never do this. Because again, the point of machine learning systems is that we want to know how our algorithm will perform. So the point of the test set is give us some estimate of how our algorithm will do on unseen data that's coming out from the wild. And if we use this strategy of training many different algorithms with different hyper parameters, and then, selecting the one which does the best on the test data. Then, it's possible, that we may have just picked the right set of hyper parameters that caused our algorithm to work quite well, but now our performance on this test set, will no longer be representative of our performance of new, unseen data. Again, you should not do this, this is a bad idea, you'll get in trouble if you do this.

------

<center>
    <image src="./images/2.2_03_training-validation-test-dataset.png"></image>
</center>
------

更常见的方法，就是将数据分为三组，大部分数据作为训练集，然后建立一个验证集，一个测试集。我们通常所做的是在训练集上用不同超参来训练算法，在验证集上进行评估，然后选择一组在验证集上表现最好的超参数。然后，当完成了这些步骤之后，完成了所有的调试，所有都完成了，再把这组在验证集上表现最佳的分类器拿出来，在测试集上跑。这才是你要写到论文中的数据，也是你要写到报告中的数据，这个数据才是告诉你你的算法在未见的新数据上表现如何。非常重要的一点是，必须分隔验证集和测试集。所以这一点非常重要，你要确保测试集数据受到严格控制。

What is much more common, is to actually split your data into three different sets. You'll partition most of your data into a training set, and then you'll create a validation set and a test set. And now what we typically do is go and train our algorithm with many different choices of hyper parameters on the training set, evaluate on the validation set, and now pick the set of hyper parameters which preforms best on the validation set. And now, after you've done all your development, you've done all your debugging, after you've dome everything, then you'd take that best performing classifier on the validation set and run it once on the test set. And that's the number that goes into your paper, that's the number that goes into your report, that's the number that actually is telling you how your algorithm is doing on unseen data. And this is really really important that you keep a very strict separation between the validation data and the test data. So this is actually super import and you want to make sure to keep your test data quite under control.

------

<center>
    <image src="./images/2.2_04_cross-validation.png"></image>
</center>
------

设定超参数的另一个策略是交叉验证。这在小数据集中更常用一些，在深度学习中不那么常用。它的理念是，我们取出测试集数据，和往常一样，保留部分数据作为最后使用的测试集，对于剩余的数据，我们不是把他们分成一个训练集和一个验证集，而是将训练数据分成很多份。在这种方法下，我们轮流将每一份都当做验证集。例如，在这里，我们使用 5 份的交叉验证，先在前 4 份上用一组超参数来训练算法，在第 5 份上验证。然后再次在 1、2、3、5 数据上训练算法，在第 4 份上验证，然后对不同份进行循环。这么做了之后，你对哪组超参数的表现更鲁棒会有更强的信心。这似乎是一种黄金法则，但事实上，在深度学习中，当我们训练大型模型时，训练本身非常消耗计算力，因此这些方法实际上不常用。

Another strategy for setting hyper parameters is called cross validation. And this is used a little bit more commonly for small data sets, not used so much in deep learning. Here the idea is we're going to take our test data as usual, hold out some test set to use at the very end, and now, for the rest of the data, rather than splitting it into a single training and validation partition, instead, we can split our training data into many different folds. And now, in this way, we've cycled through choosing which fold is going to be the validation set. So now, in this example, we're using five fold cross validation, so you would train your algorithm with one set of hyper parameters on the first four folds, evaluate the performance on fold four, and now go and retrain your algorithm on folds one, two, three, and five, evaluate on fold four, and cycle through all the different folds. And when you do it this way, you get much higher confidence about which hyper parameters are going to perform more robustly. This is kind of the gold standard to use, but, in practice in deep learning, when we're training large models and training is very computationally expensive, these doesn't get used too much in practice.

*训练集和验证集的区别是什么？*

*What's the difference between the training and the validation set?*

*回想一下 K-最近邻 分类算法，那么训练集就是一堆贴上标签的图片。要给图像分类，我们会将图片与训练集的每一个元素比较，然后将最近点的标签作为结果。我们的算法会记住训练集中的所有样本，然后我们会把验证集中的每个元素与训练集中的每个元素比较，以它作为依据判定分类器的准确性。这就是训练集和验证集的区别，算法可以看到训练集中的各个标签，但是对于验证集，算法不能直接看到它们的标签，我们只是用验证集中的标签，来检查我们算法的表现。*

*If you think about the k-nearest neighbor classifier, the training set is this set of images with labels. And to classify an image, we're going to take the image and compare it to each element in the training data, and then transfer the label from the nearest training point. Our algorithm will memorize everything in the training set, and now we'll take each element of the validation set and compare it to each element in the training data and then use this to determine what is the accuracy of our classifier when it's applied on the validation set. So this is the distinction between training and validation, where your algorithm is able to see the labels of the training set, but for the validation set, your algorithm doesn't have direct access to the labels. We only use the labels of the validation set to check how well our algorithm is doing.*

*是否可能测试集不能很好地代表真实世界中的数据？*

*Is it possible that the test set might not be able representative of data out there in the wild?*

*我们背后的统计学假设就是你的数据都互相独立，服从同一分布，所有的数据点都来自同一概率分布。*

*The underlying statistical assumption here is that your data are all independently and identically distributed, all of your data points should be drawn from the same underlying probability distribution.*

------

<center>
    <image src="./images/2.2_05_accuracy-K-plot.png"></image>
</center>
------

那么经过交叉验证，你会得到这样一张图。X 轴表示 K-最近邻 分类器中参数 K 的值，Y 轴表示分类器对不同 K 在数据集上的准确率。可以看到，在这个例子里，我们用了 5 折交叉验证，也就是说对每个 K 值，我们都对算法做了 5 次不同的测试，来了解这个算法表现如何。回到刚才的问题，选取一部分数据作为测试集来检测算法是变得更好还是更糟，使用 K 折交叉验证，也许是一个量化它好坏的办法。因此我们可以观察算法在不同验证集上的表现。同时，不光是让我们知道哪样更好，还能让我们看到算法效果的分布。当你训练一个机器学习的模型，你最后要画出这样一张画，从中可以看出准确率，算法的表现与各个超参数之间的关系，最后你可以挑选出，在验证集上表现最好的模型以及相应的超参数。这里我们看到 K= 7 时效果最好。

So then, once you've gone through this cross validation procedure, then you end up with graphs look something like this. On the X axis, we are showing the value of K for a K-nearest neighbor classifier on some problem, on the Y axis, we are showing what is the accuracy of our classifier on some dataset for different values of K. In this case, we've done five fold cross validation over the data, for each value of K we have five different examples of how well this algorithm is doing. Going back to the question about having some test sets that are better or worse for your algorithm, using k fold cross validation is maybe one way to help quantify that a little bit. And in that, we can see the variance of how this algorithm performs on different of the validation folds. And that gives you some sense of, not just what is the best, but, also, what is the distribution of that performance. So when you're training machine learning models, you end up making plots like this, where they show you what is your accuracy, or your performance as a function of you hyper parameters, and then you want to go and pick the model, or the set of hyper parameters, at the end of the day that performs the best on the validation set. Here we see that K = 7 probably works best for this problem.

## 2.2.3 KNN 的缺陷 Defect of KNN

------

<center>
    <image src="./images/2.2_06_L2-performance.png"></image>
</center>
------

其实，KNN 在图像分类中很少用到。原因包括我们刚才谈到的所有问题。一个是在测试时运算时间很长，和我们的需求不符。另一个问题在于，像欧几里得距离或者 L1 距离这样的衡量标准，用在比较图像上实在不合适。这种向量化的距离函数，不大适合表示图像之间视觉相似度。究竟我们是如何区别图像中的不同的。在接下来的例子里，我们拿左边这张女生的图片，和右边三张经过不同处理的图片，比如遮住嘴，向下平移几个像素的距离，或者把整幅图染得偏蓝。如果你计算原图和另三张图的欧氏距离，会得到相同的答案。L2 距离确实不适用于表示图像之间视觉感知的差异。

K-nearest neighbor classifier on images are actually almost never used in practice. Because,with all of these problems that we've talked about. One problem is that it's very slow at test time, which is the reverse of what we want. Another problem is that these things like Euclidean distance, or L1 distance, are really not a very good way to measure distances between images. These vectorial distance functions do not correspond very well to perceptual similarity between images. How you perceive differences between images. In this example, there's this image on the left of a girl, and then three different distorted images on the right where we've block out her mouth, shifted down by a couple pixels, or tinted the entire image blue. If you compute the Euclidean distance between the original and these three images, they all have the same L2 distance. So the L2 distance is really not doing a very good job at capturing these perceptional distances between images.

K-最近邻 算法还有另一个问题，我们称之为维度灾难。如果你还记得我们对 K-最近邻 分类器的描述，它有点像是用训练数据把样本空间分成几块。这意味着，如果我们希望分类器有好的效果，我们需要训练数据能密集地分布在空间中，否则最近邻点的实际距离可能很远，也就是说和待测样本的相似性没有那么高。而问题在于，想要密集地分布在空间中，我们需要指数倍地训练数据。这很不好，指数倍的增加从来都不是好消息。我们也根本不可能拿到那么多的图片去密布这样高维空间里的点。

Another problem with the KNN classifier has to do with something we call the curse of dimensionality. If you recall back this viewpoint we had of the KNN classifier, it's sort of dropping paint around each of the training data points and using that to sort of partition the space. So that means if we expect the KNN classifier to work well, we kind of need our training examples to cover the space quite densely. Otherwise our nearest neighbors could actually be quite far away and not actually be very similar to our testing points. And the problem is, that actually densely covering the space, means that we need a number of training examples, which is exponential in the dimension of the problem. This is very bad, exponential growth is always bad, basically, you're never going to get enough images to densely cover this space of pixels in this high dimensional space.

## 2.2.4 总结 Summary

做个小结，我们借用 KNN 介绍了图像分类的基本思路。借助训练集的图片和相应的标记，我们可以预测测试集中数据的分类。

We're using KNN to introduce this idea of image classification. We have a training set of images and labels, and we use that to predict these labels on the test set.





